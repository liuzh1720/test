{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword extraction with `TfidfVectorizer`\n",
    "\n",
    "Scikit-learn's `CountVectorizer` class creates matrices of word counts and is frequently uses in text-classification tasks. The related [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class creates matrices of [Term Freqeuency-Inverse Document Frequency](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) (TFIDF) values that reflect not just the presence of individual words, but each word's importance. One use for `TfidfVectorizer` is extracting keywords from documents. Let's use it to extract keywords from a book chapter on machine learning. Begin by loading the chapter from a text file and showing the first few paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Software developers are accustomed to solving problems algorithmically. Given a recipe, or algorithm, it's not difficult to write an app that hashes a password or computes a monthly mortgage payment. You code up the algorithm, feed it input, and receive output in return. It's another proposition altogether to write code that determines whether a photo contains a cat or a dog. You can try to do it algorithmically, but the minute you get it working, I'll send you a cat or dog picture that breaks the algorithm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine learning takes a different approach to turning input into output. Rather than rely on you to implement an algorithm, it examines a dataset consisting of inputs and outputs and learns how to generate output of its own. Under the hood, special algorithms called learning algorithms build mathematical models of the data and codify the relationship between data going in and data coming out. Once trained in this manner, a model can accept new inputs and generate outputs consistent with the ones in the training data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To use machine learning to distinguish between cats and dogs, you don't code a cat-vs-dog algorithm. Instead, you train a machine-learning model with cat and dog photos. Success depends on the learning algorithm used and the quality and volume of the training data. Part of becoming a machine-learning engineer is familiarizing yourself with the various learning algorithms and developing an intuition for when to use one versus another. That intuition begins with an examination of machine learning itself.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Machine Learning?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At an existential level, machine learning (ML) is a means for finding patterns in numbers and exploiting those patterns to make predictions. Train a model with thousands (or millions) of xs and ys, and let it learn from the data so that given a new x, it can predict what y will be. Learning is the process by which ML finds patterns that can be used to predict future outputs, and it's where the 'learning' in 'machine learning' comes from.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0\n",
       "0            Software developers are accustomed to solving problems algorithmically. Given a recipe, or algorithm, it's not difficult to write an app that hashes a password or computes a monthly mortgage payment. You code up the algorithm, feed it input, and receive output in return. It's another proposition altogether to write code that determines whether a photo contains a cat or a dog. You can try to do it algorithmically, but the minute you get it working, I'll send you a cat or dog picture that breaks the algorithm.\n",
       "1  Machine learning takes a different approach to turning input into output. Rather than rely on you to implement an algorithm, it examines a dataset consisting of inputs and outputs and learns how to generate output of its own. Under the hood, special algorithms called learning algorithms build mathematical models of the data and codify the relationship between data going in and data coming out. Once trained in this manner, a model can accept new inputs and generate outputs consistent with the ones in the training data.\n",
       "2                  To use machine learning to distinguish between cats and dogs, you don't code a cat-vs-dog algorithm. Instead, you train a machine-learning model with cat and dog photos. Success depends on the learning algorithm used and the quality and volume of the training data. Part of becoming a machine-learning engineer is familiarizing yourself with the various learning algorithms and developing an intuition for when to use one versus another. That intuition begins with an examination of machine learning itself.\n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    What is Machine Learning?\n",
       "4                                                                                    At an existential level, machine learning (ML) is a means for finding patterns in numbers and exploiting those patterns to make predictions. Train a model with thousands (or millions) of xs and ys, and let it learn from the data so that given a new x, it can predict what y will be. Learning is the process by which ML finds patterns that can be used to predict future outputs, and it's where the 'learning' in 'machine learning' comes from."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Data/chapter-1.txt', sep='\\r\\n', engine='python', header=None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the paragraphs and show the first few lines of the resulting word matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1s 0s</th>\n",
       "      <th>add column</th>\n",
       "      <th>annual income</th>\n",
       "      <th>build mathematical</th>\n",
       "      <th>cat dog</th>\n",
       "      <th>classification models</th>\n",
       "      <th>column contains</th>\n",
       "      <th>credit card</th>\n",
       "      <th>data data</th>\n",
       "      <th>data points</th>\n",
       "      <th>...</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>setosa versicolor</th>\n",
       "      <th>spending score</th>\n",
       "      <th>spending scores</th>\n",
       "      <th>supervised learning</th>\n",
       "      <th>train machine</th>\n",
       "      <th>training data</th>\n",
       "      <th>unsupervised learning</th>\n",
       "      <th>use following</th>\n",
       "      <th>versicolor virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.526645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297392</td>\n",
       "      <td>0.257343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.727929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.670370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1s 0s  add column  annual income  build mathematical   cat dog  \\\n",
       "0  0.000000         0.0            0.0            0.000000  1.000000   \n",
       "1  0.000000         0.0            0.0            0.526645  0.000000   \n",
       "2  0.000000         0.0            0.0            0.000000  0.329181   \n",
       "3  0.000000         0.0            0.0            0.000000  0.000000   \n",
       "4  0.000000         0.0            0.0            0.000000  0.000000   \n",
       "5  0.727929         0.0            0.0            0.000000  0.000000   \n",
       "6  0.000000         0.0            0.0            0.000000  0.000000   \n",
       "7  0.670370         0.0            0.0            0.000000  0.000000   \n",
       "8  0.000000         0.0            0.0            0.000000  0.000000   \n",
       "9  0.000000         0.0            0.0            0.000000  0.000000   \n",
       "\n",
       "   classification models  column contains  credit card  data data  \\\n",
       "0                    0.0          0.00000          0.0        0.0   \n",
       "1                    0.0          0.00000          0.0        0.0   \n",
       "2                    0.0          0.00000          0.0        0.0   \n",
       "3                    0.0          0.00000          0.0        0.0   \n",
       "4                    0.0          0.00000          0.0        0.0   \n",
       "5                    0.0          0.40287          0.0        0.0   \n",
       "6                    0.0          0.00000          0.0        0.0   \n",
       "7                    0.0          0.00000          0.0        0.0   \n",
       "8                    0.0          0.00000          0.0        0.0   \n",
       "9                    0.0          0.00000          0.0        0.0   \n",
       "\n",
       "   data points  ...  sepal width  setosa versicolor  spending score  \\\n",
       "0          0.0  ...          0.0                0.0             0.0   \n",
       "1          0.0  ...          0.0                0.0             0.0   \n",
       "2          0.0  ...          0.0                0.0             0.0   \n",
       "3          0.0  ...          0.0                0.0             0.0   \n",
       "4          0.0  ...          0.0                0.0             0.0   \n",
       "5          0.0  ...          0.0                0.0             0.0   \n",
       "6          0.0  ...          0.0                0.0             0.0   \n",
       "7          0.0  ...          0.0                0.0             0.0   \n",
       "8          0.0  ...          0.0                0.0             0.0   \n",
       "9          0.0  ...          0.0                0.0             0.0   \n",
       "\n",
       "   spending scores  supervised learning  train machine  training data  \\\n",
       "0              0.0                  0.0       0.000000       0.000000   \n",
       "1              0.0                  0.0       0.000000       0.411714   \n",
       "2              0.0                  0.0       0.297392       0.257343   \n",
       "3              0.0                  0.0       0.000000       0.000000   \n",
       "4              0.0                  0.0       0.000000       0.000000   \n",
       "5              0.0                  0.0       0.000000       0.000000   \n",
       "6              0.0                  0.0       0.000000       0.000000   \n",
       "7              0.0                  0.0       0.000000       0.000000   \n",
       "8              0.0                  0.0       0.000000       0.000000   \n",
       "9              0.0                  0.0       0.000000       0.000000   \n",
       "\n",
       "   unsupervised learning  use following  versicolor virginica  \n",
       "0                    0.0            0.0                   0.0  \n",
       "1                    0.0            0.0                   0.0  \n",
       "2                    0.0            0.0                   0.0  \n",
       "3                    0.0            0.0                   0.0  \n",
       "4                    0.0            0.0                   0.0  \n",
       "5                    0.0            0.0                   0.0  \n",
       "6                    0.0            0.0                   0.0  \n",
       "7                    0.0            0.0                   0.0  \n",
       "8                    0.0            0.0                   0.0  \n",
       "9                    0.0            0.0                   0.0  \n",
       "\n",
       "[10 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2, 2), min_df=0.025, max_df=0.5, stop_words='english')\n",
    "word_matrix = vectorizer.fit_transform(df[0])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "wm_df = pd.DataFrame(data=word_matrix.toarray(), columns=feature_names)\n",
    "wm_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sparse word matrix into a coordinate matrix that includes only non-zero values (weights) and the rows and columns in which they appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4)\t1.0\n",
      "  (1, 49)\t0.41171364214971173\n",
      "  (1, 28)\t0.5266452223745365\n",
      "  (1, 3)\t0.5266452223745365\n",
      "  (1, 21)\t0.43970283823932543\n",
      "  (1, 25)\t0.28712873491214824\n",
      "  (2, 20)\t0.27483761002183926\n",
      "  (2, 22)\t0.26560327297719427\n",
      "  (2, 48)\t0.29739224366595657\n",
      "  (2, 49)\t0.25734287700964276\n",
      "  (2, 21)\t0.27483761002183926\n",
      "  (2, 25)\t0.7178827918222094\n",
      "  (2, 4)\t0.3291812143547189\n",
      "  (3, 25)\t1.0\n",
      "  (4, 26)\t0.6079427215514522\n",
      "  (4, 25)\t0.7939808859869445\n",
      "  (5, 6)\t0.4028697432073993\n",
      "  (5, 18)\t0.38145874437527655\n",
      "  (5, 10)\t0.4028697432073993\n",
      "  (5, 0)\t0.7279293690706851\n",
      "  (6, 30)\t0.5768531568260111\n",
      "  (6, 37)\t0.5211465511802166\n",
      "  (6, 25)\t0.6290045370685583\n",
      "  (7, 30)\t0.7420272038414925\n",
      "  (7, 0)\t0.6703697701710424\n",
      "  :\t:\n",
      "  (91, 40)\t1.0\n",
      "  (93, 49)\t0.3686419838367719\n",
      "  (93, 28)\t0.47154993101664205\n",
      "  (93, 3)\t0.47154993101664205\n",
      "  (93, 21)\t0.39370307415818434\n",
      "  (93, 25)\t0.514181195949137\n",
      "  (94, 7)\t0.25937135995965965\n",
      "  (94, 19)\t0.46864782871828475\n",
      "  (94, 47)\t0.39376023290373574\n",
      "  (94, 50)\t0.19150502328554675\n",
      "  (94, 23)\t0.6278294062758754\n",
      "  (94, 5)\t0.24558675593114754\n",
      "  (94, 26)\t0.21655246888606403\n",
      "  (94, 25)\t0.1414101320845122\n",
      "  (95, 32)\t0.46610115002835284\n",
      "  (95, 38)\t0.2981076149481205\n",
      "  (95, 40)\t0.28226432588728073\n",
      "  (95, 29)\t0.2262835108521731\n",
      "  (95, 47)\t0.4525670217043462\n",
      "  (95, 50)\t0.22010566529441705\n",
      "  (95, 20)\t0.4977877281500323\n",
      "  (95, 21)\t0.24889386407501615\n",
      "  (96, 17)\t0.7306029456939581\n",
      "  (96, 29)\t0.5545762379110629\n",
      "  (96, 25)\t0.3983271671474636\n"
     ]
    }
   ],
   "source": [
    "coo_matrix = word_matrix.tocoo()\n",
    "print(coo_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tuples from the column numbers and weights in the coordinate matrix. Then sort the tuples in descending order based on the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1.0) => cat dog\n",
      "(25, 1.0) => machine learning\n",
      "(25, 1.0) => machine learning\n",
      "(25, 1.0) => machine learning\n",
      "(25, 1.0) => machine learning\n",
      "(50, 1.0) => unsupervised learning\n",
      "(12, 1.0) => following code\n",
      "(29, 1.0) => means clustering\n",
      "(29, 1.0) => means clustering\n",
      "(9, 1.0) => data points\n",
      "(47, 1.0) => supervised learning\n",
      "(32, 1.0) => nearest neighbors\n",
      "(32, 1.0) => nearest neighbors\n",
      "(32, 1.0) => nearest neighbors\n",
      "(32, 1.0) => nearest neighbors\n",
      "(31, 1.0) => model accuracy\n",
      "(27, 1.0) => making predictions\n",
      "(36, 1.0) => predict class\n",
      "(49, 1.0) => training data\n",
      "(40, 1.0) => scikit learn\n",
      "(32, 0.8805448238444277) => nearest neighbors\n",
      "(37, 0.8561751021506758) => real world\n",
      "(25, 0.803856205496376) => machine learning\n",
      "(25, 0.7939808859869445) => machine learning\n",
      "(49, 0.7731187523324384) => training data\n",
      "(39, 0.7676246648600459) => right number\n",
      "(2, 0.7500525583741241) => annual income\n",
      "(32, 0.7441198535306921) => nearest neighbors\n",
      "(30, 0.7420272038414925) => millions rows\n",
      "(6, 0.7420272038414925) => column contains\n",
      "(9, 0.7399158628045803) => data points\n",
      "(13, 0.7376325237851317) => following statements\n",
      "(19, 0.7353775931681876) => labeled data\n",
      "(37, 0.7344073797929055) => real world\n",
      "(17, 0.7306029456939581) => jupyter notebook\n",
      "(0, 0.7279293690706851) => 1s 0s\n",
      "(46, 0.7218931373084843) => spending scores\n",
      "(25, 0.7178827918222094) => machine learning\n",
      "(29, 0.7168242079334923) => means clustering\n",
      "(29, 0.7168242079334923) => means clustering\n",
      "(23, 0.7084869306845735) => learning models\n",
      "(33, 0.7071067811865476) => number clusters\n",
      "(39, 0.7071067811865476) => right number\n",
      "(33, 0.7071067811865476) => number clusters\n",
      "(39, 0.7071067811865476) => right number\n",
      "(1, 0.7071067811865476) => add column\n",
      "(41, 0.7071067811865476) => segment customers\n",
      "(5, 0.7037578744864946) => classification models\n",
      "(50, 0.6972539386195831) => unsupervised learning\n",
      "(50, 0.6972539386195831) => unsupervised learning\n",
      "(50, 0.6939068212915545) => unsupervised learning\n",
      "(25, 0.6845742955493805) => machine learning\n",
      "(48, 0.6801256079913934) => train machine\n",
      "(20, 0.6787089217814357) => learning algorithm\n",
      "(51, 0.6752023843666262) => use following\n",
      "(29, 0.6726994246839768) => means clustering\n",
      "(0, 0.6703697701710424) => 1s 0s\n",
      "(0, 0.6703697701710424) => 1s 0s\n",
      "(9, 0.6613782273982346) => data points\n",
      "(37, 0.6503674936951619) => real world\n",
      "(0, 0.6503674936951619) => 1s 0s\n",
      "(9, 0.6408996597740573) => data points\n",
      "(29, 0.6373134305385414) => means clustering\n",
      "(17, 0.6359354687693229) => jupyter notebook\n",
      "(25, 0.6290045370685583) => machine learning\n",
      "(23, 0.6278294062758754) => learning models\n",
      "(41, 0.6241007262832584) => segment customers\n",
      "(50, 0.619913912867442) => unsupervised learning\n",
      "(26, 0.6079427215514522) => make predictions\n",
      "(22, 0.6074253494015961) => learning model\n",
      "(20, 0.6026409911330227) => learning algorithm\n",
      "(13, 0.6021379106039388) => following statements\n",
      "(27, 0.6014439028675274) => making predictions\n",
      "(23, 0.594823672095326) => learning models\n",
      "(45, 0.5875716412871428) => spending score\n",
      "(15, 0.5875716412871428) => income spending\n",
      "(45, 0.5875716412871428) => spending score\n",
      "(15, 0.5875716412871428) => income spending\n",
      "(46, 0.5851682335794984) => spending scores\n",
      "(12, 0.5851682335794984) => following code\n",
      "(30, 0.5768531568260111) => millions rows\n",
      "(31, 0.5657375217907783) => model accuracy\n",
      "(47, 0.5656508960478019) => supervised learning\n",
      "(32, 0.564279999559708) => nearest neighbors\n",
      "(49, 0.564279999559708) => training data\n",
      "(12, 0.5638314313493284) => following code\n",
      "(51, 0.5613878132083908) => use following\n",
      "(11, 0.5595611884647269) => datasets like\n",
      "(30, 0.5595611884647269) => millions rows\n",
      "(25, 0.5578013866175753) => machine learning\n",
      "(2, 0.5563444371163124) => annual income\n",
      "(2, 0.5563444371163124) => annual income\n",
      "(29, 0.5545762379110629) => means clustering\n",
      "(40, 0.5497781594090745) => scikit learn\n",
      "(48, 0.5433625732975231) => train machine\n",
      "(51, 0.5409181088439147) => use following\n",
      "(18, 0.5298226336223203) => label column\n",
      "(28, 0.5266452223745365) => mathematical models\n",
      "(3, 0.5266452223745365) => build mathematical\n",
      "(31, 0.526231321643103) => model accuracy\n",
      "(8, 0.526231321643103) => data data\n",
      "(11, 0.526231321643103) => datasets like\n",
      "(21, 0.524171258635692) => learning algorithms\n",
      "(37, 0.5211465511802166) => real world\n",
      "(25, 0.5166857792288073) => machine learning\n",
      "(25, 0.514181195949137) => machine learning\n",
      "(11, 0.5134579738259717) => datasets like\n",
      "(6, 0.5134579738259717) => column contains\n",
      "(41, 0.5115535290919585) => segment customers\n",
      "(37, 0.5111043510219243) => real world\n",
      "(45, 0.5065949667294068) => spending score\n",
      "(15, 0.5065949667294068) => income spending\n",
      "(33, 0.5065949667294068) => number clusters\n",
      "(23, 0.506559498473125) => learning models\n",
      "(38, 0.5018640752209794) => regression classification\n",
      "(10, 0.5018640752209794) => data scientists\n",
      "(35, 0.5) => petal width\n",
      "(34, 0.5) => petal length\n",
      "(43, 0.5) => sepal width\n",
      "(42, 0.5) => sepal length\n",
      "(47, 0.4998901342511416) => supervised learning\n",
      "(20, 0.4977877281500323) => learning algorithm\n",
      "(5, 0.4861696299796273) => classification models\n",
      "(18, 0.4861696299796273) => label column\n",
      "(22, 0.48528124372751885) => learning model\n",
      "(29, 0.4827173253309481) => means clustering\n",
      "(2, 0.4796713656799762) => annual income\n",
      "(26, 0.47234149947909015) => make predictions\n",
      "(28, 0.47154993101664205) => mathematical models\n",
      "(3, 0.47154993101664205) => build mathematical\n",
      "(8, 0.46990818526810524) => data data\n",
      "(19, 0.46864782871828475) => labeled data\n",
      "(22, 0.46849281984084057) => learning model\n",
      "(32, 0.46610115002835284) => nearest neighbors\n",
      "(46, 0.4621528967566216) => spending scores\n",
      "(0, 0.4621528967566216) => 1s 0s\n",
      "(25, 0.45775357113688714) => machine learning\n",
      "(10, 0.45593647959569067) => data scientists\n",
      "(28, 0.45593647959569067) => mathematical models\n",
      "(3, 0.45593647959569067) => build mathematical\n",
      "(47, 0.4525670217043462) => supervised learning\n",
      "(49, 0.4422746959462308) => training data\n",
      "(29, 0.44074195954401685) => means clustering\n",
      "(21, 0.43970283823932543) => learning algorithms\n",
      "(24, 0.4309876875284723) => low spending\n",
      "(16, 0.4309876875284723) => incomes low\n",
      "(14, 0.4309876875284723) => high incomes\n",
      "(50, 0.42870910860126965) => unsupervised learning\n",
      "(25, 0.42717466671388643) => machine learning\n",
      "(20, 0.4190127412341422) => learning algorithm\n",
      "(21, 0.4190127412341422) => learning algorithms\n",
      "(20, 0.4128385301026845) => learning algorithm\n",
      "(36, 0.4119067757311599) => predict class\n",
      "(49, 0.41171364214971173) => training data\n",
      "(49, 0.4113900683843245) => training data\n",
      "(25, 0.4104431778683697) => machine learning\n",
      "(8, 0.40699193453118504) => data data\n",
      "(25, 0.4062815959548538) => machine learning\n",
      "(6, 0.4028697432073993) => column contains\n",
      "(10, 0.4028697432073993) => data scientists\n",
      "(24, 0.39952901367606747) => low spending\n",
      "(16, 0.39952901367606747) => incomes low\n",
      "(14, 0.39952901367606747) => high incomes\n",
      "(22, 0.3989674659070634) => learning model\n",
      "(25, 0.3983271671474636) => machine learning\n",
      "(9, 0.39735337634100004) => data points\n",
      "(21, 0.39735337634100004) => learning algorithms\n",
      "(47, 0.39376023290373574) => supervised learning\n",
      "(21, 0.39370307415818434) => learning algorithms\n",
      "(1, 0.3933255742665142) => add column\n",
      "(24, 0.3933255742665142) => low spending\n",
      "(16, 0.3933255742665142) => incomes low\n",
      "(14, 0.3933255742665142) => high incomes\n",
      "(25, 0.3924847083509714) => machine learning\n",
      "(26, 0.39233235961520574) => make predictions\n",
      "(27, 0.3917571980615879) => making predictions\n",
      "(52, 0.389821556236359) => versicolor virginica\n",
      "(44, 0.389821556236359) => setosa versicolor\n",
      "(1, 0.389821556236359) => add column\n",
      "(17, 0.389821556236359) => jupyter notebook\n",
      "(46, 0.38936728402848236) => spending scores\n",
      "(12, 0.38936728402848236) => following code\n",
      "(18, 0.38145874437527655) => label column\n",
      "(47, 0.3809482187543103) => supervised learning\n",
      "(9, 0.38066720368441453) => data points\n",
      "(23, 0.37915028732924827) => learning models\n",
      "(51, 0.37354394099375515) => use following\n",
      "(7, 0.37259639219632973) => credit card\n",
      "(13, 0.37242181181412043) => following statements\n",
      "(4, 0.3716296432513177) => cat dog\n",
      "(49, 0.3686419838367719) => training data\n",
      "(26, 0.3665595920155999) => make predictions\n",
      "(47, 0.36125646319792853) => supervised learning\n",
      "(18, 0.3554970719708412) => label column\n",
      "(46, 0.3553421942731911) => spending scores\n",
      "(36, 0.35392527587640576) => predict class\n",
      "(19, 0.35392527587640576) => labeled data\n",
      "(48, 0.35392527587640576) => train machine\n",
      "(12, 0.3521765586342421) => following code\n",
      "(48, 0.3521765586342421) => train machine\n",
      "(51, 0.3409015834018214) => use following\n",
      "(19, 0.3366148255887518) => labeled data\n",
      "(36, 0.3357414354155537) => predict class\n",
      "(52, 0.3303913695476211) => versicolor virginica\n",
      "(44, 0.3303913695476211) => setosa versicolor\n",
      "(35, 0.3303913695476211) => petal width\n",
      "(34, 0.3303913695476211) => petal length\n",
      "(43, 0.3303913695476211) => sepal width\n",
      "(42, 0.3303913695476211) => sepal length\n",
      "(4, 0.3291812143547189) => cat dog\n",
      "(22, 0.32838565863700264) => learning model\n",
      "(25, 0.32790922544088724) => machine learning\n",
      "(25, 0.31656512520167623) => machine learning\n",
      "(23, 0.31609335369122366) => learning models\n",
      "(22, 0.31609335369122366) => learning model\n",
      "(52, 0.3146380988467465) => versicolor virginica\n",
      "(44, 0.3146380988467465) => setosa versicolor\n",
      "(35, 0.3146380988467465) => petal width\n",
      "(34, 0.3146380988467465) => petal length\n",
      "(43, 0.3146380988467465) => sepal width\n",
      "(42, 0.3146380988467465) => sepal length\n",
      "(38, 0.3146380988467465) => regression classification\n",
      "(22, 0.31453156103212515) => learning model\n",
      "(9, 0.3134687305313628) => data points\n",
      "(13, 0.31283232137684347) => following statements\n",
      "(26, 0.31108549780016076) => make predictions\n",
      "(47, 0.3089339527615277) => supervised learning\n",
      "(25, 0.30507462960625437) => machine learning\n",
      "(23, 0.3006332589811738) => learning models\n",
      "(50, 0.30049963847799754) => unsupervised learning\n",
      "(23, 0.29985322757978966) => learning models\n",
      "(36, 0.2984855343894466) => predict class\n",
      "(38, 0.2981076149481205) => regression classification\n",
      "(40, 0.2979162772641291) => scikit learn\n",
      "(5, 0.2979162772641291) => classification models\n",
      "(48, 0.29739224366595657) => train machine\n",
      "(47, 0.29736977431594175) => supervised learning\n",
      "(49, 0.290527640721641) => training data\n",
      "(25, 0.28712873491214824) => machine learning\n",
      "(51, 0.28635549882846556) => use following\n",
      "(40, 0.28226432588728073) => scikit learn\n",
      "(47, 0.28209162126329296) => supervised learning\n",
      "(26, 0.27584798408472355) => make predictions\n",
      "(50, 0.27510393119258275) => unsupervised learning\n",
      "(20, 0.27483761002183926) => learning algorithm\n",
      "(21, 0.27483761002183926) => learning algorithms\n",
      "(25, 0.26958617175642563) => machine learning\n",
      "(22, 0.26560327297719427) => learning model\n",
      "(20, 0.26269537670418824) => learning algorithm\n",
      "(7, 0.25937135995965965) => credit card\n",
      "(49, 0.25734287700964276) => training data\n",
      "(21, 0.24889386407501615) => learning algorithms\n",
      "(25, 0.24857809209082235) => machine learning\n",
      "(32, 0.24597355512157087) => nearest neighbors\n",
      "(5, 0.24558675593114754) => classification models\n",
      "(29, 0.2262835108521731) => means clustering\n",
      "(50, 0.22010566529441705) => unsupervised learning\n",
      "(7, 0.21951968586736945) => credit card\n",
      "(26, 0.21655246888606403) => make predictions\n",
      "(25, 0.21253201496629093) => machine learning\n",
      "(19, 0.1983207092692564) => labeled data\n",
      "(50, 0.19150502328554675) => unsupervised learning\n",
      "(50, 0.16208081940968688) => unsupervised learning\n",
      "(25, 0.1414101320845122) => machine learning\n"
     ]
    }
   ],
   "source": [
    "tuples = list(zip(coo_matrix.col, coo_matrix.data))\n",
    "sorted_tuples = sorted(tuples, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for _, tuple in enumerate(sorted_tuples):\n",
    "    print(f'{tuple} => {feature_names[tuple[0]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the top keywords by weight and use `set` to eliminate duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat dog', 'machine learning'}\n"
     ]
    }
   ],
   "source": [
    "keywords = []\n",
    "num_keywords = 5\n",
    "\n",
    "for tuple in sorted_tuples[:num_keywords]:\n",
    "    keywords.append(feature_names[tuple[0]])\n",
    "    \n",
    "print(set(keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyword extraction sometimes works better when you sum all the values for a given word and select the words yielding the highest sums rather than the words with the highest individual values. Sort keywords based on that criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning             13.819216\n",
      "nearest neighbors             6.901019\n",
      "means clustering              6.447980\n",
      "unsupervised learning         5.286333\n",
      "supervised learning           4.542468\n",
      "training data                 4.519290\n",
      "data points                   4.133683\n",
      "learning models               3.733430\n",
      "real world                    3.273201\n",
      "learning model                3.184781\n",
      "1s 0s                         3.181189\n",
      "learning algorithm            3.148522\n",
      "following code                2.890544\n",
      "use following                 2.778309\n",
      "learning algorithms           2.697675\n",
      "make predictions              2.642662\n",
      "spending scores               2.513924\n",
      "predict class                 2.400059\n",
      "annual income                 2.342413\n",
      "train machine                 2.226982\n",
      "right number                  2.181838\n",
      "scikit learn                  2.129959\n",
      "labeled data                  2.092886\n",
      "model accuracy                2.091969\n",
      "following statements          2.025025\n",
      "making predictions            1.993201\n",
      "number clusters               1.920809\n",
      "millions rows                 1.878442\n",
      "segment customers             1.842761\n",
      "jupyter notebook              1.756360\n",
      "label column                  1.752948\n",
      "classification models         1.733431\n",
      "cat dog                       1.700811\n",
      "spending score                1.681738\n",
      "income spending               1.681738\n",
      "column contains               1.658355\n",
      "datasets like                 1.599250\n",
      "add column                    1.490254\n",
      "mathematical models           1.454132\n",
      "build mathematical            1.454132\n",
      "data data                     1.403131\n",
      "data scientists               1.360670\n",
      "high incomes                  1.223842\n",
      "low spending                  1.223842\n",
      "incomes low                   1.223842\n",
      "petal length                  1.145029\n",
      "sepal width                   1.145029\n",
      "sepal length                  1.145029\n",
      "petal width                   1.145029\n",
      "regression classification     1.114610\n",
      "setosa versicolor             1.034851\n",
      "versicolor virginica          1.034851\n",
      "credit card                   0.851487\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "summed_weights = pd.Series(dtype='float32')\n",
    "\n",
    "for col_name, col_data in wm_df.items():\n",
    "    summed_weights = pd.concat([summed_weights, pd.Series({ col_name: np.sum(col_data) })])\n",
    "    \n",
    "sorted_summed_weights = summed_weights.sort_values(ascending=False)\n",
    "print(sorted_summed_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the top keywords by summed weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine learning', 'nearest neighbors', 'means clustering', 'unsupervised learning', 'supervised learning']\n"
     ]
    }
   ],
   "source": [
    "keywords = []\n",
    "\n",
    "for idx, _ in sorted_summed_weights[:num_keywords].items():\n",
    "    keywords.append(idx)\n",
    "    \n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you read **chapter-1.txt**, you'll see that these keywords highlight some of the most important concepts introduced in the chapter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
